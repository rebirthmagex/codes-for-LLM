{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zCyOHUWWpwu"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DS4SD/docling/blob/main/docs/examples/rag_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFVeIiwyWpww"
      },
      "source": [
        "# RAG with LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElPqmyIZWpwy"
      },
      "source": [
        "| Step | Tech | Execution |\n",
        "| --- | --- | --- |\n",
        "| Embedding | Hugging Face / Sentence Transformers | üíª Local |\n",
        "| Vector store | Milvus | üíª Local |\n",
        "| Gen AI | Hugging Face Inference API | üåê Remote |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "702dSkiHWpwz"
      },
      "source": [
        "This example leverages the\n",
        "[LangChain Docling integration](../../integrations/langchain/), along with a Milvus\n",
        "vector store, as well as sentence-transformers embeddings.\n",
        "\n",
        "The presented `DoclingLoader` component enables you to:\n",
        "- use various document types in your LLM applications with ease and speed, and\n",
        "- leverage Docling's rich format for advanced, document-native grounding.\n",
        "\n",
        "`DoclingLoader` supports two different export modes:\n",
        "- `ExportType.MARKDOWN`: if you want to capture each input document as a separate\n",
        "  LangChain document, or\n",
        "- `ExportType.DOC_CHUNKS` (default): if you want to have each input document chunked and\n",
        "  to then capture each individual chunk as a separate LangChain document downstream.\n",
        "\n",
        "The example allows exploring both modes via parameter `EXPORT_TYPE`; depending on the\n",
        "value set, the example pipeline is then set up accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-4bc8RNWpw8"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDxoFy86Wpw-"
      },
      "source": [
        "- üëâ For best conversion speed, use GPU acceleration whenever available; e.g. if running on Colab, use GPU-enabled runtime.\n",
        "- Notebook uses HuggingFace's Inference API; for increased LLM quota, token can be provided via env var `HF_TOKEN`.\n",
        "- Requirements can be installed as shown below (`--no-warn-conflicts` meant for Colab's pre-populated Python env; feel free to remove for stricter usage):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzjJKZ23Wpw_"
      },
      "outputs": [],
      "source": [
        "%pip install -q --progress-bar off --no-warn-conflicts langchain-docling langchain-core langchain-huggingface langchain_milvus langchain python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVtYOsJGWpxB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from tempfile import mkdtemp\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_docling.loader import ExportType\n",
        "\n",
        "\n",
        "def _get_env_from_colab_or_os(key):\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "\n",
        "        try:\n",
        "            return userdata.get(key)\n",
        "        except userdata.SecretNotFoundError:\n",
        "            pass\n",
        "    except ImportError:\n",
        "        pass\n",
        "    return os.getenv(key)\n",
        "\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# https://github.com/huggingface/transformers/issues/5486:\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "HF_TOKEN = _get_env_from_colab_or_os(\"HF_TOKEN\")\n",
        "FILE_PATH = [\"https://arxiv.org/pdf/2408.09869\"]  # Docling Technical Report\n",
        "EMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "GEN_MODEL_ID = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "EXPORT_TYPE = ExportType.DOC_CHUNKS\n",
        "QUESTION = \"Which are the main AI models in Docling?\"\n",
        "PROMPT = PromptTemplate.from_template(\n",
        "    \"Context information is below.\\n---------------------\\n{context}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {input}\\nAnswer:\\n\",\n",
        ")\n",
        "TOP_K = 3\n",
        "MILVUS_URI = str(Path(mkdtemp()) / \"docling.db\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoK5kQW2WpxC"
      },
      "source": [
        "## Document loading\n",
        "\n",
        "Now we can instantiate our loader and load documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISlo7oV_WpxD",
        "outputId": "239d2f50-603c-42b4-cd2d-28b723a71f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "7735c59363d6416fb7bddbaf0d5fb3f7",
            "a97f5888316247129aa22eca699c11f3",
            "2e959c827682438abe720aad00c49f48",
            "9b2de7d55b064565a6806451b37b46d8",
            "f4786f665dcb41a9aac78278a874f545",
            "916642c178614aedab64deff75c0e6ee",
            "d807f37eb6a3401b9ffdb224356bdb6d",
            "7bf03d2daa9f4d4aa8bad632e58f217a",
            "4be7a5db41c04c4db03624de6d0c8c66",
            "3e9c9d267379481db67d62761609032c",
            "18b7e95b12074fc7ae5e330afcd7f347",
            "ab21aea4cfa746cc80182181bdac63f1",
            "0413c74cda7f4561a8fca70b096e66ae",
            "d1165178b84c48afa68068038259595d",
            "86631c2afe8e4e10a90e66d79151ca44",
            "8ba0b3cf028549bbaa9f01b0d54ff2df",
            "6f806da97ca9413f850acd77c76698c5",
            "6a02d65931624725be41853fa947a125",
            "54ceaece698b4756a04c1d8196f8f655",
            "ca916c34d6fb4fee9219ad1eaaac4bf1",
            "5e3fc5c59dca49dda329cfbbc9970867",
            "f83eedcf66cf4840b9d26c454a6b6029",
            "e4c82f3fee7745419d73e603d561ccef",
            "d26fb0552eea4a608e4079414f832197",
            "3e4a6f5ce56740f88b8937d39a6f0b8b",
            "a3403ad2c1a84360b5011b91d49f0b57",
            "41119b9f26934702adcb9e7dd6ef0789",
            "2d970bbbd4014f6391b5656665c391b8",
            "7fc71c0536294d44b088cf1e4bda8dc2",
            "bab66dfc5f28405f820cc44f6fda13ca",
            "09a974c2423f42668c9afd02299182ef",
            "cde744b4d76a4082804413da5e2eb735",
            "388c4677dfeb4502948d348ae0ef8db5",
            "e1e103fa793544efa45c95666e43a981",
            "145409240c1446f9b44d12eb0cdefad4",
            "38a5b12d3c854ed886865edff9c2e85d",
            "0929a909a2264aa781813e165f91444b",
            "62ab1b8718004166b190eae68191ae2c",
            "3c7605f5971f41369a480f84925baa04",
            "18e3277bb4484495a9d0db74b1d8b6e1",
            "d5bd4cb92eef4196a2790d9fbe3a461e",
            "3a6f52193806457ab5395f8803c56ec2",
            "59ea9081027744168ceb7d6f58acb91e",
            "67154df05e9344a5998786182b9bcb7e"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7735c59363d6416fb7bddbaf0d5fb3f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab21aea4cfa746cc80182181bdac63f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4c82f3fee7745419d73e603d561ccef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1e103fa793544efa45c95666e43a981"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n",
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (648 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "from langchain_docling import DoclingLoader\n",
        "\n",
        "from docling.chunking import HybridChunker\n",
        "\n",
        "loader = DoclingLoader(\n",
        "    file_path=FILE_PATH,\n",
        "    export_type=EXPORT_TYPE,\n",
        "    chunker=HybridChunker(tokenizer=EMBED_MODEL_ID),\n",
        ")\n",
        "\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uthrmxg9WpxE"
      },
      "source": [
        "> Note: a message saying `\"Token indices sequence length is longer than the specified\n",
        "maximum sequence length...\"` can be ignored in this case ‚Äî details\n",
        "[here](https://github.com/DS4SD/docling-core/issues/119#issuecomment-2577418826)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eCaqHvFWpxG"
      },
      "source": [
        "Determining the splits:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tS86XWuxWpxG"
      },
      "outputs": [],
      "source": [
        "if EXPORT_TYPE == ExportType.DOC_CHUNKS:\n",
        "    splits = docs\n",
        "elif EXPORT_TYPE == ExportType.MARKDOWN:\n",
        "    from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
        "\n",
        "    splitter = MarkdownHeaderTextSplitter(\n",
        "        headers_to_split_on=[\n",
        "            (\"#\", \"Header_1\"),\n",
        "            (\"##\", \"Header_2\"),\n",
        "            (\"###\", \"Header_3\"),\n",
        "        ],\n",
        "    )\n",
        "    splits = [split for doc in docs for split in splitter.split_text(doc.page_content)]\n",
        "else:\n",
        "    raise ValueError(f\"Unexpected export type: {EXPORT_TYPE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWIvNjdRWpxM"
      },
      "source": [
        "Inspecting some sample splits:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aB3YpgGHWpxM",
        "outputId": "161966c4-fb64-4beb-f252-2d0a29449adc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- d.page_content='Docling Technical Report\\nVersion 1.0\\nChristoph Auer Maksym Lysak Ahmed Nassar Michele Dolfi Nikolaos Livathinos Panos Vagenas Cesar Berrospi Ramis Matteo Omenetti Fabian Lindlbauer Kasper Dinkla Lokesh Mishra Yusik Kim Shubham Gupta Rafael Teixeira de Lima Valery Weber Lucas Morin Ingmar Meijer Viktor Kuropiatnyk Peter W. J. Staar\\nAI4K Group, IBM Research R¬® uschlikon, Switzerland'\n",
            "- d.page_content='Abstract\\nThis technical report introduces Docling , an easy to use, self-contained, MITlicensed open-source package for PDF document conversion. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. The code interface allows for easy extensibility and addition of new features and models.'\n",
            "- d.page_content='1 Introduction\\nConverting PDF documents back into a machine-processable format has been a major challenge for decades due to their huge variability in formats, weak standardization and printing-optimized characteristic, which discards most structural features and metadata. With the advent of LLMs and popular application patterns such as retrieval-augmented generation (RAG), leveraging the rich content embedded in PDFs has become ever more relevant. In the past decade, several powerful document understanding solutions have emerged on the market, most of which are commercial software, cloud offerings [3] and most recently, multi-modal vision-language models. As of today, only a handful of open-source tools cover PDF conversion, leaving a significant feature and quality gap to proprietary solutions.\\nWith Docling , we open-source a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition we developed and presented in the recent past [12, 13, 9]. Docling is designed as a simple, self-contained python library with permissive license, running entirely locally on commodity hardware. Its code architecture allows for easy extensibility and addition of new features and models.\\nHere is what Docling delivers today:\\n¬∑ Converts PDF documents to JSON or Markdown format, stable and lightning fast\\n¬∑ Understands detailed page layout, reading order, locates figures and recovers table structures\\n¬∑ Extracts metadata from the document, such as title, authors, references and language\\n¬∑ Optionally applies OCR, e.g. for scanned PDFs\\n¬∑ Can be configured to be optimal for batch-mode (i.e high throughput, low time-to-solution) or interactive mode (compromise on efficiency, low time-to-solution)\\n¬∑ Can leverage different accelerators (GPU, MPS, etc).'\n",
            "- d.page_content='2 Getting Started\\nTo use Docling, you can simply install the docling package from PyPI. Documentation and examples are available in our GitHub repository at github.com/DS4SD/docling. All required model assets 1 are downloaded to a local huggingface datasets cache on first use, unless you choose to pre-install the model assets in advance.\\nDocling provides an easy code interface to convert PDF documents from file system, URLs or binary streams, and retrieve the output in either JSON or Markdown format. For convenience, separate methods are offered to convert single documents or batches of documents. A basic usage example is illustrated below. Further examples are available in the Doclign code repository.\\nfrom docling.document_converter import DocumentConverter Large\\nsource = \"https://arxiv.org/pdf/2206.01062\" # PDF path or URL converter = DocumentConverter() result = converter.convert_single(source) print(result.render_as_markdown()) # output: \"## DocLayNet: A Human -Annotated Dataset for Document -Layout Analysis [...]\"\\nOptionally, you can configure custom pipeline features and runtime options, such as turning on or off features (e.g. OCR, table structure recognition), enforcing limits on the input document size, and defining the budget of CPU threads. Advanced usage examples and options are documented in the README file. Docling also provides a Dockerfile to demonstrate how to install and run it inside a container.'\n",
            "- d.page_content='3 Processing pipeline\\nDocling implements a linear pipeline of operations, which execute sequentially on each given document (see Fig. 1). Each document is first parsed by a PDF backend, which retrieves the programmatic text tokens, consisting of string content and its coordinates on the page, and also renders a bitmap image of each page to support downstream operations. Then, the standard model pipeline applies a sequence of AI models independently on every page in the document to extract features and content, such as layout and table structures. Finally, the results from all pages are aggregated and passed through a post-processing stage, which augments metadata, detects the document language, infers reading-order and eventually assembles a typed document object which can be serialized to JSON or Markdown.'\n",
            "...\n"
          ]
        }
      ],
      "source": [
        "for d in splits[:5]:\n",
        "    print(f\"- {d.page_content=}\")\n",
        "print(\"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FksOpPoxWpxM"
      },
      "source": [
        "## Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaY3X8xxWpxN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from tempfile import mkdtemp\n",
        "\n",
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_milvus import Milvus\n",
        "\n",
        "embedding = HuggingFaceEmbeddings(model_name=EMBED_MODEL_ID)\n",
        "\n",
        "\n",
        "milvus_uri = str(Path(mkdtemp()) / \"docling.db\")  # or set as needed\n",
        "\n",
        "vectorstore = Milvus.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embedding,\n",
        "    collection_name=\"docling_demo\",\n",
        "    connection_args={\"uri\": milvus_uri},\n",
        "    index_params={\"index_type\": \"FLAT\"},\n",
        "    drop_old=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MYNh3xsgdC14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdmte3jNWpxN"
      },
      "source": [
        "## RAG"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": TOP_K})\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=GEN_MODEL_ID,\n",
        "    huggingfacehub_api_token=HF_TOKEN,\n",
        "    task=\"text-generation\"  # Explicitly specify task\n",
        ")\n",
        "\n",
        "\n",
        "def clip_text(text, threshold=100):\n",
        "    return f\"{text[:threshold]}...\" if len(text) > threshold else text"
      ],
      "metadata": {
        "id": "mWFLdUuXeyD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryut0AUcWpxO",
        "outputId": "69e6b2c9-21bb-490c-fe2a-7242397e16d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:\n",
            "Which are the main AI models in Docling?\n",
            "\n",
            "Answer:\n",
            "Docling initially releases two main AI models:\n",
            "1. A layout analysis model: An accurate object-detector for page elements.\n",
            "2. TableFormer: A state-of-the-art table structure recognition model.\n",
            "\n",
            "Source 1:\n",
            "  text: \"3.2 AI models\\nAs part of Docling, we initially release two highly capable AI models to the open-source community, which have been developed and published recently by our team. The first model is a layout analysis model, an accurate object-detector for page elements [13]. The second model is TableFormer [12, 9], a state-of-the-art table structure re...\"\n",
            "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/50', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 3, 'bbox': {'l': 108.0, 't': 404.87298583984375, 'r': 504.00299072265625, 'b': 330.8659973144531, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 608]}]}], 'headings': ['3.2 AI models'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
            "  source: https://arxiv.org/pdf/2408.09869\n",
            "\n",
            "Source 2:\n",
            "  text: \"3 Processing pipeline\\nDocling implements a linear pipeline of operations, which execute sequentially on each given document (see Fig. 1). Each document is first parsed by a PDF backend, which retrieves the programmatic text tokens, consisting of string content and its coordinates on the page, and also renders a bitmap image of each page to support ...\"\n",
            "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/26', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 2, 'bbox': {'l': 108.0, 't': 272.7489929199219, 'r': 504.00299072265625, 'b': 176.9239959716797, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 796]}]}], 'headings': ['3 Processing pipeline'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
            "  source: https://arxiv.org/pdf/2408.09869\n",
            "\n",
            "Source 3:\n",
            "  text: \"6 Future work and contributions\\nDocling is designed to allow easy extension of the model library and pipelines. In the future, we plan to extend Docling with several more models, such as a figure-classifier model, an equationrecognition model, a code-recognition model and more. This will help improve the quality of conversion for specific types of ...\"\n",
            "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/76', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 108.0, 't': 322.20001220703125, 'r': 504.00299072265625, 'b': 259.1029968261719, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 543]}]}, {'self_ref': '#/texts/77', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 108.0, 't': 251.6540069580078, 'r': 504.00299072265625, 'b': 199.0780029296875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 402]}]}], 'headings': ['6 Future work and contributions'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
            "  source: https://arxiv.org/pdf/2408.09869\n"
          ]
        }
      ],
      "source": [
        "question_answer_chain = create_stuff_documents_chain(llm, PROMPT)\n",
        "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
        "# Definir a tarefa explicitamente (gera√ß√£o de texto)\n",
        "\n",
        "resp_dict = rag_chain.invoke({\"input\": QUESTION})\n",
        "\n",
        "clipped_answer = clip_text(resp_dict[\"answer\"], threshold=200)\n",
        "print(f\"Question:\\n{resp_dict['input']}\\n\\nAnswer:\\n{clipped_answer}\")\n",
        "for i, doc in enumerate(resp_dict[\"context\"]):\n",
        "    print()\n",
        "    print(f\"Source {i+1}:\")\n",
        "    print(f\"  text: {json.dumps(clip_text(doc.page_content, threshold=350))}\")\n",
        "    for key in doc.metadata:\n",
        "        if key != \"pk\":\n",
        "            val = doc.metadata.get(key)\n",
        "            clipped_val = clip_text(val) if isinstance(val, str) else val\n",
        "            print(f\"  {key}: {clipped_val}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkhLVHTfWpxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aee4c5ab-3fa3-4ac0-b683-d3f23bb098fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:\n",
            "What is Docling?\n",
            "\n",
            "Answer:\n",
            "Docling is an open-source, extensible, and high-performance document conversion and extraction system. It's designed to convert documents, such as PDFs, into structured formats like JSON and Markdown....\n",
            "\n",
            "Source 1:\n",
            "  text: \"6 Future work and contributions\\nDocling is designed to allow easy extension of the model library and pipelines. In the future, we plan to extend Docling with several more models, such as a figure-classifier model, an equationrecognition model, a code-recognition model and more. This will help improve the quality of conversion for specific types of ...\"\n",
            "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/76', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 108.0, 't': 322.20001220703125, 'r': 504.00299072265625, 'b': 259.1029968261719, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 543]}]}, {'self_ref': '#/texts/77', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 108.0, 't': 251.6540069580078, 'r': 504.00299072265625, 'b': 199.0780029296875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 402]}]}], 'headings': ['6 Future work and contributions'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
            "  source: https://arxiv.org/pdf/2408.09869\n",
            "\n",
            "Source 2:\n",
            "  text: \"Appendix\\nIn this section, we illustrate a few examples of Docling's output in Markdown and JSON.\"\n",
            "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/99', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 7, 'bbox': {'l': 108.0, 't': 693.4099731445312, 'r': 463.7539978027344, 'b': 684.8579711914062, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 87]}]}], 'headings': ['Appendix'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
            "  source: https://arxiv.org/pdf/2408.09869\n",
            "\n",
            "Source 3:\n",
            "  text: \"3.3 Assembly\\nIn the final pipeline stage, Docling assembles all prediction results produced on each page into a well-defined datatype that encapsulates a converted document, as defined in the auxiliary package docling-core . The generated document object is passed through a post-processing model which leverages several algorithms to augment feature...\"\n",
            "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/62', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 4, 'bbox': {'l': 108.0, 't': 505.81201171875, 'r': 504.00299072265625, 'b': 431.80499267578125, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 622]}]}], 'headings': ['3.3 Assembly'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
            "  source: https://arxiv.org/pdf/2408.09869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "question_answer_chain = create_stuff_documents_chain(llm, PROMPT)\n",
        "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
        "# Definir a tarefa explicitamente (gera√ß√£o de texto)\n",
        "\n",
        "QUESTION = \"What is Docling?\"\n",
        "resp_dict = rag_chain.invoke({\"input\": QUESTION})\n",
        "\n",
        "clipped_answer = clip_text(resp_dict[\"answer\"], threshold=200)\n",
        "print(f\"Question:\\n{resp_dict['input']}\\n\\nAnswer:\\n{clipped_answer}\")\n",
        "for i, doc in enumerate(resp_dict[\"context\"]):\n",
        "    print()\n",
        "    print(f\"Source {i+1}:\")\n",
        "    print(f\"  text: {json.dumps(clip_text(doc.page_content, threshold=350))}\")\n",
        "    for key in doc.metadata:\n",
        "        if key != \"pk\":\n",
        "            val = doc.metadata.get(key)\n",
        "            clipped_val = clip_text(val) if isinstance(val, str) else val\n",
        "            print(f\"  {key}: {clipped_val}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_answer_chain = create_stuff_documents_chain(llm, PROMPT)\n",
        "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
        "# Definir a tarefa explicitamente (gera√ß√£o de texto)\n",
        "\n",
        "QUESTION = \"How can I install and use Docling?\"\n",
        "resp_dict = rag_chain.invoke({\"input\": QUESTION})\n",
        "\n",
        "clipped_answer = clip_text(resp_dict[\"answer\"], threshold=1000)\n",
        "print(f\"Question:\\n{resp_dict['input']}\\n\\nAnswer:\\n{clipped_answer}\")\n",
        "for i, doc in enumerate(resp_dict[\"context\"]):\n",
        "    print()\n",
        "    print(f\"Source {i+1}:\")\n",
        "    print(f\"  text: {json.dumps(clip_text(doc.page_content, threshold=350))}\")\n",
        "    for key in doc.metadata:\n",
        "        if key != \"pk\":\n",
        "            val = doc.metadata.get(key)\n",
        "            clipped_val = clip_text(val) if isinstance(val, str) else val\n",
        "            print(f\"  {key}: {clipped_val}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FQKLe8SjCVl",
        "outputId": "d25bf360-eeb8-4f8b-abff-29dc0c9eaffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:\n",
            "How can I install and use Docling?\n",
            "\n",
            "Answer:\n",
            "To install Docling, you can use pip by running the following command:\n",
            "```bash\n",
            "pip install docling\n",
            "```\n",
            "After installation, you can use Docling to convert PDF documents into JSON or Markdown format. Here's a basic usage example:\n",
            "```python\n",
            "from docling.document_converter import DocumentConverter\n",
            "\n",
            "# PDF path or URL\n",
            "source = \"https://arxiv.org/pdf/2206.01062\"\n",
            "\n",
            "# Initialize DocumentConverter\n",
            "converter = DocumentConverter()\n",
            "\n",
            "# Convert a single document\n",
            "result = converter.convert_single(source)\n",
            "\n",
            "# Print the output as Markdown\n",
            "print(result.render_as_markdown())\n",
            "```\n",
            "This will output the content of the PDF in Markdown format. For more advanced usage and options, you can refer to the documentation and examples available in the Docling GitHub repository at `github.com/DS4SD/docling`.\n",
            "\n",
            "If you want to run Docling inside a container, you can use the provided Dockerfile. However, the instructions for doing so are not provided in the given context.\n",
            "\n",
            "Source 1:\n",
            "  text: \"6 Future work and contributions\\nDocling is designed to allow easy extension of the model library and pipelines. In the future, we plan to extend Docling with several more models, such as a figure-classifier model, an equationrecognition model, a code-recognition model and more. This will help improve the quality of conversion for specific types of ...\"\n",
            "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/76', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 108.0, 't': 322.20001220703125, 'r': 504.00299072265625, 'b': 259.1029968261719, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 543]}]}, {'self_ref': '#/texts/77', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 108.0, 't': 251.6540069580078, 'r': 504.00299072265625, 'b': 199.0780029296875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 402]}]}], 'headings': ['6 Future work and contributions'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
            "  source: https://arxiv.org/pdf/2408.09869\n",
            "\n",
            "Source 2:\n",
            "  text: \"2 Getting Started\\nTo use Docling, you can simply install the docling package from PyPI. Documentation and examples are available in our GitHub repository at github.com/DS4SD/docling. All required model assets 1 are downloaded to a local huggingface datasets cache on first use, unless you choose to pre-install the model assets in advance.\\nDocling pr...\"\n",
            "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/20', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 2, 'bbox': {'l': 108.0, 't': 547.8200073242188, 'r': 504.00299072265625, 'b': 506.36199951171875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 321]}]}, {'self_ref': '#/texts/21', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 2, 'bbox': {'l': 108.0, 't': 498.5249938964844, 'r': 504.00299072265625, 'b': 457.2460021972656, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 371]}]}, {'self_ref': '#/texts/22', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 2, 'bbox': {'l': 108.75299835205078, 't': 448.9110107421875, 'r': 491.33599853515625, 'b': 391.62799072265625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 62]}]}, {'self_ref': '#/texts/23', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'code', 'prov': [{'page_no': 2, 'bbox': {'l': 108.78500366210938, 't': 428.9849853515625, 'r': 460.3999938964844, 'b': 381.6659851074219, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 259]}]}, {'self_ref': '#/texts/24', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 2, 'bbox': {'l': 108.0, 't': 367.8370056152344, 'r': 504.00299072265625, 'b': 315.64898681640625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 403]}]}], 'headings': ['2 Getting Started'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
            "  source: https://arxiv.org/pdf/2408.09869\n",
            "\n",
            "Source 3:\n",
            "  text: \"Appendix\\nIn this section, we illustrate a few examples of Docling's output in Markdown and JSON.\"\n",
            "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/99', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 7, 'bbox': {'l': 108.0, 't': 693.4099731445312, 'r': 463.7539978027344, 'b': 684.8579711914062, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 87]}]}], 'headings': ['Appendix'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
            "  source: https://arxiv.org/pdf/2408.09869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_answer_chain = create_stuff_documents_chain(llm, PROMPT)\n",
        "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
        "# Definir a tarefa explicitamente (gera√ß√£o de texto)\n",
        "\n",
        "QUESTION = \"What is the performance of Docling?\"\n",
        "resp_dict = rag_chain.invoke({\"input\": QUESTION})\n",
        "\n",
        "clipped_answer = clip_text(resp_dict[\"answer\"], threshold=2000)\n",
        "print(f\"Question:\\n{resp_dict['input']}\\n\\nAnswer:\\n{clipped_answer}\")\n",
        "for i, doc in enumerate(resp_dict[\"context\"]):\n",
        "    print()\n",
        "    print(f\"Source {i+1}:\")\n",
        "    print(f\"  text: {json.dumps(clip_text(doc.page_content, threshold=350))}\")\n",
        "    for key in doc.metadata:\n",
        "        if key != \"pk\":\n",
        "            val = doc.metadata.get(key)\n",
        "            clipped_val = clip_text(val) if isinstance(val, str) else val\n",
        "            print(f\"  {key}: {clipped_val}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIqfxmeRjWVL",
        "outputId": "2584d348-017b-42fc-efd1-0ee1efc1a2d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:\n",
            "What is the performance of Docling?\n",
            "\n",
            "Answer:\n",
            "Based on the provided information, Docling has the following performance characteristics when processing a test dataset of 225 pages with default settings and OCR disabled:\n",
            "\n",
            "- **Time-to-solution (TTS)**:\n",
            "  - Apple M3 Max (4 threads, native backend): 177 seconds\n",
            "  - Apple M3 Max (4 threads, pypdfium backend): 103 seconds\n",
            "  - Apple M3 Max (16 threads, native backend): 167 seconds\n",
            "  - Apple M3 Max (16 threads, pypdfium backend): 92 seconds\n",
            "  - Intel Xeon E5-2690 (4 threads, native backend): 375 seconds\n",
            "  - Intel Xeon E5-2690 (4 threads, pypdfium backend): 239 seconds\n",
            "  - Intel Xeon E5-2690 (16 threads, native backend): 244 seconds\n",
            "  - Intel Xeon E5-2690 (16 threads, pypdfium backend): 143 seconds\n",
            "\n",
            "- **Throughput** (pages per second):\n",
            "  - Apple M3 Max (4 threads, native backend): 1.27\n",
            "  - Apple M3 Max (4 threads, pypdfium backend): 2.18\n",
            "  - Apple M3 Max (16 threads, native backend): 1.34\n",
            "  - Apple M3 Max (16 threads, pypdfium backend): 2.45\n",
            "  - Intel Xeon E5-2690 (4 threads, native backend): 0.60\n",
            "  - Intel Xeon E5-2690 (4 threads, pypdfium backend): 0.94\n",
            "  - Intel Xeon E5-2690 (16 threads, native backend): 0.92\n",
            "  - Intel Xeon E5-2690 (16 threads, pypdfium backend): 1.57\n",
            "\n",
            "- **Memory usage** (resident set size):\n",
            "  - Apple M3 Max and Intel Xeon E5-2690 (native backend): ~6.20 GB\n",
            "  - Apple M3 Max and Intel Xeon E5-2690 (pypdfium backend): ~2.56 GB (for Ubuntu) or ~2.\n",
            "\n",
            "Source 1:\n",
            "  text: \"4 Performance\\nIn this section, we establish some reference numbers for the processing speed of Docling and the resource budget it requires. All tests in this section are run with default options on our standard test set distributed with Docling, which consists of three papers from arXiv and two IBM Redbooks, with a total of 225 pages. Measurements ...\"\n",
            "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/67', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 4, 'bbox': {'l': 108.0, 't': 220.35400390625, 'r': 504.00299072265625, 'b': 135.43800354003906, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 750]}]}, {'self_ref': '#/texts/68', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 4, 'bbox': {'l': 108.0, 't': 127.60199737548828, 'r': 504.00299072265625, 'b': 97.23200225830078, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 290]}]}, {'self_ref': '#/texts/69', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 4, 'bbox': {'l': 108.0, 't': 89.3949966430664, 'r': 504.00299072265625, 'b': 69.93399810791016, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 192]}]}, {'self_ref': '#/texts/71', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 108.0, 't': 716.5230102539062, 'r': 504.00299072265625, 'b': 697.06201171875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 121]}]}, {'self_ref': '#/texts/72', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 5, 'bbox': {'l': 108.0, 't': 685.3480224609375, 'r': 504.00299072265625, 'b': 644.0689697265625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 383]}]}], 'headings': ['4 Performance'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
            "  source: https://arxiv.org/pdf/2408.09869\n",
            "\n",
            "Source 2:\n",
            "  text: \"4 Performance\\nTable 1: Runtime characteristics of Docling with the standard model pipeline and settings, on our test dataset of 225 pages, on two different systems. OCR is disabled. We show the time-to-solution (TTS), computed throughput in pages per second, and the peak memory used (resident set size) for both the Docling-native PDF backend and fo...\"\n",
            "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/0', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'table', 'prov': [{'page_no': 5, 'bbox': {'l': 133.71226501464844, 't': 635.0570068359375, 'r': 477.50604248046875, 'b': 542.84033203125, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 0]}]}], 'headings': ['4 Performance'], 'captions': ['Table 1: Runtime characteristics of Docling with the standard model pipeline and settings, on our test dataset of 225 pages, on two different systems. OCR is disabled. We show the time-to-solution (TTS), computed throughput in pages per second, and the peak memory used (resident set size) for both the Docling-native PDF backend and for the pypdfium backend, using 4 and 16 threads.'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
            "  source: https://arxiv.org/pdf/2408.09869\n",
            "\n",
            "Source 3:\n",
            "  text: \"6 Future work and contributions\\nDocling is designed to allow easy extension of the model library and pipelines. In the future, we plan to extend Docling with several more models, such as a figure-classifier model, an equationrecognition model, a code-recognition model and more. This will help improve the quality of conversion for specific types of ...\"\n",
            "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/76', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 108.0, 't': 322.20001220703125, 'r': 504.00299072265625, 'b': 259.1029968261719, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 543]}]}, {'self_ref': '#/texts/77', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 108.0, 't': 251.6540069580078, 'r': 504.00299072265625, 'b': 199.0780029296875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 402]}]}], 'headings': ['6 Future work and contributions'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
            "  source: https://arxiv.org/pdf/2408.09869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_answer_chain = create_stuff_documents_chain(llm, PROMPT)\n",
        "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
        "# Definir a tarefa explicitamente (gera√ß√£o de texto)\n",
        "\n",
        "QUESTION = \"What are the future plans for Docling?\"\n",
        "resp_dict = rag_chain.invoke({\"input\": QUESTION})\n",
        "\n",
        "clipped_answer = clip_text(resp_dict[\"answer\"], threshold=2000)\n",
        "print(f\"Question:\\n{resp_dict['input']}\\n\\nAnswer:\\n{clipped_answer}\")\n",
        "for i, doc in enumerate(resp_dict[\"context\"]):\n",
        "    print()\n",
        "    print(f\"Source {i+1}:\")\n",
        "    print(f\"  text: {json.dumps(clip_text(doc.page_content, threshold=350))}\")\n",
        "    for key in doc.metadata:\n",
        "        if key != \"pk\":\n",
        "            val = doc.metadata.get(key)\n",
        "            clipped_val = clip_text(val) if isinstance(val, str) else val\n",
        "            print(f\"  {key}: {clipped_val}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJmWR7wAkQBO",
        "outputId": "beaecc86-5d82-4e9f-887c-f10d9d0a2835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:\n",
            "What are the future plans for Docling?\n",
            "\n",
            "Answer:\n",
            "- Extend Docling with more models such as a figure-classifier model, an equation recognition model, a code recognition model, etc. to improve conversion quality and augment extracted document metadata.\n",
            "- Invest in testing and optimizing GPU acceleration.\n",
            "- Improve the Docling-native PDF backend.\n",
            "- Encourage contributions and inputs from the community to extend the model library and pipelines.\n",
            "- If Docling is used in projects, cite the technical report.\n",
            "\n",
            "Source 1:\n",
            "  text: \"6 Future work and contributions\\nDocling is designed to allow easy extension of the model library and pipelines. In the future, we plan to extend Docling with several more models, such as a figure-classifier model, an equationrecognition model, a code-recognition model and more. This will help improve the quality of conversion for specific types of ...\"\n",
            "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/76', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 108.0, 't': 322.20001220703125, 'r': 504.00299072265625, 'b': 259.1029968261719, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 543]}]}, {'self_ref': '#/texts/77', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 108.0, 't': 251.6540069580078, 'r': 504.00299072265625, 'b': 199.0780029296875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 402]}]}], 'headings': ['6 Future work and contributions'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
            "  source: https://arxiv.org/pdf/2408.09869\n",
            "\n",
            "Source 2:\n",
            "  text: \"3.3 Assembly\\nIn the final pipeline stage, Docling assembles all prediction results produced on each page into a well-defined datatype that encapsulates a converted document, as defined in the auxiliary package docling-core . The generated document object is passed through a post-processing model which leverages several algorithms to augment feature...\"\n",
            "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/62', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 4, 'bbox': {'l': 108.0, 't': 505.81201171875, 'r': 504.00299072265625, 'b': 431.80499267578125, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 622]}]}], 'headings': ['3.3 Assembly'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
            "  source: https://arxiv.org/pdf/2408.09869\n",
            "\n",
            "Source 3:\n",
            "  text: \"4 Performance\\nIn this section, we establish some reference numbers for the processing speed of Docling and the resource budget it requires. All tests in this section are run with default options on our standard test set distributed with Docling, which consists of three papers from arXiv and two IBM Redbooks, with a total of 225 pages. Measurements ...\"\n",
            "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/67', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 4, 'bbox': {'l': 108.0, 't': 220.35400390625, 'r': 504.00299072265625, 'b': 135.43800354003906, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 750]}]}, {'self_ref': '#/texts/68', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 4, 'bbox': {'l': 108.0, 't': 127.60199737548828, 'r': 504.00299072265625, 'b': 97.23200225830078, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 290]}]}, {'self_ref': '#/texts/69', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 4, 'bbox': {'l': 108.0, 't': 89.3949966430664, 'r': 504.00299072265625, 'b': 69.93399810791016, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 192]}]}, {'self_ref': '#/texts/71', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 108.0, 't': 716.5230102539062, 'r': 504.00299072265625, 'b': 697.06201171875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 121]}]}, {'self_ref': '#/texts/72', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'caption', 'prov': [{'page_no': 5, 'bbox': {'l': 108.0, 't': 685.3480224609375, 'r': 504.00299072265625, 'b': 644.0689697265625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 383]}]}], 'headings': ['4 Performance'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
            "  source: https://arxiv.org/pdf/2408.09869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Criando o CacheDB"
      ],
      "metadata": {
        "id": "f0JQK3xdEyfP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eD0v_FsoE8M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mudando a codifica√ß√£o de ANSI para UTF-8"
      ],
      "metadata": {
        "id": "gUo8QW6TwMlk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lHyP0Az7ZNq",
        "outputId": "436d2075-9913-41b8-ceb3-308519982e3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANSI_X3.4-1968\n"
          ]
        }
      ],
      "source": [
        "import locale\n",
        "print(locale.getpreferredencoding())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hc6H7ce17eZ2"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "‚úÖ Updated HuggingFaceEndpoint documentation to explicitly define task=\"text-generation\":\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=GEN_MODEL_ID,\n",
        "    huggingfacehub_api_token=HF_TOKEN,\n",
        "    task=\"text-generation\"  # Explicitly specify task\n",
        ")\n",
        "\n",
        "‚úÖ Added a deprecation warning note and recommended using InferenceClient:\n",
        "\n",
        "from huggingface_hub import InferenceClient\n",
        "from langchain.llms.huggingface_hub import HuggingFaceHub\n",
        "\n",
        "client = InferenceClient(model=GEN_MODEL_ID, token=HF_TOKEN)\n",
        "\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=GEN_MODEL_ID,\n",
        "    huggingfacehub_api_token=HF_TOKEN,\n",
        "    client=client,\n",
        ")"
      ],
      "metadata": {
        "id": "bISaUUSbeS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from huggingface_hub import InferenceClient\n",
        "from langchain.llms.huggingface_hub import HuggingFaceHub\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": TOP_K})\n",
        "\n",
        "client = InferenceClient(model=GEN_MODEL_ID, token=HF_TOKEN)\n",
        "\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=GEN_MODEL_ID,\n",
        "    huggingfacehub_api_token=HF_TOKEN,\n",
        "    client=client,\n",
        ")\n",
        "\n",
        "\n",
        "def clip_text(text, threshold=100):\n",
        "    return f\"{text[:threshold]}...\" if len(text) > threshold else text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jdz6og2ey2O",
        "outputId": "f7484e2b-d9cf-4c0f-98c6-016a26dd5045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-16320e0fd7e2>:10: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
            "  llm = HuggingFaceHub(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ux3bmnRWWpxO"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": TOP_K})\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=GEN_MODEL_ID,\n",
        "    huggingfacehub_api_token=HF_TOKEN,\n",
        ")\n",
        "\n",
        "\n",
        "def clip_text(text, threshold=100):\n",
        "    return f\"{text[:threshold]}...\" if len(text) > threshold else text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Instalando bibliotecas da GPU"
      ],
      "metadata": {
        "id": "c6oH6Q3SRst0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhZmayzvGQ9Y",
        "outputId": "e2e14551-2526-4bc8-c98a-7f79f02a45f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hySUlInGXSu",
        "outputId": "14aa8f3e-7723-4598-bd4a-777d065f01aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.5.1+cu124\n",
            "CUDA available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U langchain langchain-community\n",
        "\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain import hub\n",
        "\n",
        "retrieval_qa_chat_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=GEN_MODEL_ID,\n",
        "    huggingfacehub_api_token=HF_TOKEN,\n",
        ")\n",
        "# retriever = ...\n",
        "combine_docs_chain = create_stuff_documents_chain(\n",
        "    llm, retrieval_qa_chat_prompt\n",
        ")\n",
        "retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)\n",
        "\n",
        "chain.invoke({\"input\": \"...\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hmn6F7-Bck_x",
        "outputId": "bc88b555-8e42-4334-b49b-598fa8ed63fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.18)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.17)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.35)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.7.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'ellipsis' object has no attribute 'with_config'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-5c286e0ae224>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretrieval_qa_chat_prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mretrieval_chain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_retrieval_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretriever\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombine_docs_chain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"...\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/retrieval.py\u001b[0m in \u001b[0;36mcreate_retrieval_chain\u001b[0;34m(retriever, combine_docs_chain)\u001b[0m\n\u001b[1;32m     63\u001b[0m     retrieval_chain = (\n\u001b[1;32m     64\u001b[0m         RunnablePassthrough.assign(\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretrieval_docs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"retrieve_documents\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         ).assign(answer=combine_docs_chain)\n\u001b[1;32m     67\u001b[0m     ).with_config(run_name=\"retrieval_chain\")\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ellipsis' object has no attribute 'with_config'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gUo8QW6TwMlk"
      ],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7735c59363d6416fb7bddbaf0d5fb3f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a97f5888316247129aa22eca699c11f3",
              "IPY_MODEL_2e959c827682438abe720aad00c49f48",
              "IPY_MODEL_9b2de7d55b064565a6806451b37b46d8"
            ],
            "layout": "IPY_MODEL_f4786f665dcb41a9aac78278a874f545"
          }
        },
        "a97f5888316247129aa22eca699c11f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_916642c178614aedab64deff75c0e6ee",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d807f37eb6a3401b9ffdb224356bdb6d",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "2e959c827682438abe720aad00c49f48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bf03d2daa9f4d4aa8bad632e58f217a",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4be7a5db41c04c4db03624de6d0c8c66",
            "value": 350
          }
        },
        "9b2de7d55b064565a6806451b37b46d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e9c9d267379481db67d62761609032c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_18b7e95b12074fc7ae5e330afcd7f347",
            "value": "‚Äá350/350‚Äá[00:00&lt;00:00,‚Äá31.0kB/s]"
          }
        },
        "f4786f665dcb41a9aac78278a874f545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "916642c178614aedab64deff75c0e6ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d807f37eb6a3401b9ffdb224356bdb6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bf03d2daa9f4d4aa8bad632e58f217a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4be7a5db41c04c4db03624de6d0c8c66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e9c9d267379481db67d62761609032c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18b7e95b12074fc7ae5e330afcd7f347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab21aea4cfa746cc80182181bdac63f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0413c74cda7f4561a8fca70b096e66ae",
              "IPY_MODEL_d1165178b84c48afa68068038259595d",
              "IPY_MODEL_86631c2afe8e4e10a90e66d79151ca44"
            ],
            "layout": "IPY_MODEL_8ba0b3cf028549bbaa9f01b0d54ff2df"
          }
        },
        "0413c74cda7f4561a8fca70b096e66ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f806da97ca9413f850acd77c76698c5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6a02d65931624725be41853fa947a125",
            "value": "vocab.txt:‚Äá100%"
          }
        },
        "d1165178b84c48afa68068038259595d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54ceaece698b4756a04c1d8196f8f655",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca916c34d6fb4fee9219ad1eaaac4bf1",
            "value": 231508
          }
        },
        "86631c2afe8e4e10a90e66d79151ca44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e3fc5c59dca49dda329cfbbc9970867",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f83eedcf66cf4840b9d26c454a6b6029",
            "value": "‚Äá232k/232k‚Äá[00:00&lt;00:00,‚Äá3.83MB/s]"
          }
        },
        "8ba0b3cf028549bbaa9f01b0d54ff2df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f806da97ca9413f850acd77c76698c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a02d65931624725be41853fa947a125": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54ceaece698b4756a04c1d8196f8f655": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca916c34d6fb4fee9219ad1eaaac4bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e3fc5c59dca49dda329cfbbc9970867": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f83eedcf66cf4840b9d26c454a6b6029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4c82f3fee7745419d73e603d561ccef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d26fb0552eea4a608e4079414f832197",
              "IPY_MODEL_3e4a6f5ce56740f88b8937d39a6f0b8b",
              "IPY_MODEL_a3403ad2c1a84360b5011b91d49f0b57"
            ],
            "layout": "IPY_MODEL_41119b9f26934702adcb9e7dd6ef0789"
          }
        },
        "d26fb0552eea4a608e4079414f832197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d970bbbd4014f6391b5656665c391b8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7fc71c0536294d44b088cf1e4bda8dc2",
            "value": "tokenizer.json:‚Äá100%"
          }
        },
        "3e4a6f5ce56740f88b8937d39a6f0b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bab66dfc5f28405f820cc44f6fda13ca",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09a974c2423f42668c9afd02299182ef",
            "value": 466247
          }
        },
        "a3403ad2c1a84360b5011b91d49f0b57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cde744b4d76a4082804413da5e2eb735",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_388c4677dfeb4502948d348ae0ef8db5",
            "value": "‚Äá466k/466k‚Äá[00:00&lt;00:00,‚Äá7.97MB/s]"
          }
        },
        "41119b9f26934702adcb9e7dd6ef0789": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d970bbbd4014f6391b5656665c391b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fc71c0536294d44b088cf1e4bda8dc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bab66dfc5f28405f820cc44f6fda13ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09a974c2423f42668c9afd02299182ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cde744b4d76a4082804413da5e2eb735": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "388c4677dfeb4502948d348ae0ef8db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1e103fa793544efa45c95666e43a981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_145409240c1446f9b44d12eb0cdefad4",
              "IPY_MODEL_38a5b12d3c854ed886865edff9c2e85d",
              "IPY_MODEL_0929a909a2264aa781813e165f91444b"
            ],
            "layout": "IPY_MODEL_62ab1b8718004166b190eae68191ae2c"
          }
        },
        "145409240c1446f9b44d12eb0cdefad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c7605f5971f41369a480f84925baa04",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_18e3277bb4484495a9d0db74b1d8b6e1",
            "value": "special_tokens_map.json:‚Äá100%"
          }
        },
        "38a5b12d3c854ed886865edff9c2e85d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5bd4cb92eef4196a2790d9fbe3a461e",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a6f52193806457ab5395f8803c56ec2",
            "value": 112
          }
        },
        "0929a909a2264aa781813e165f91444b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59ea9081027744168ceb7d6f58acb91e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_67154df05e9344a5998786182b9bcb7e",
            "value": "‚Äá112/112‚Äá[00:00&lt;00:00,‚Äá9.80kB/s]"
          }
        },
        "62ab1b8718004166b190eae68191ae2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c7605f5971f41369a480f84925baa04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18e3277bb4484495a9d0db74b1d8b6e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5bd4cb92eef4196a2790d9fbe3a461e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a6f52193806457ab5395f8803c56ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59ea9081027744168ceb7d6f58acb91e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67154df05e9344a5998786182b9bcb7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}